{"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":27825,"sourceType":"modelInstanceVersion","modelInstanceId":22009}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":895.907459,"end_time":"2024-02-21T09:35:28.067368","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-02-21T09:20:32.159909","version":"2.5.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Install dependencies\n\nInstall Keras and KerasNLP","metadata":{"id":"z9oy3QUmXtSd","papermill":{"duration":0.008324,"end_time":"2024-02-21T09:20:35.821692","exception":false,"start_time":"2024-02-21T09:20:35.813368","status":"completed"},"tags":[]}},{"cell_type":"code","source":"!pip install wurlitzer\n!pip install keras==2.15.0","metadata":{"execution":{"iopub.status.busy":"2024-05-06T18:35:13.500940Z","iopub.execute_input":"2024-05-06T18:35:13.504558Z","iopub.status.idle":"2024-05-06T18:35:40.027427Z","shell.execute_reply.started":"2024-05-06T18:35:13.504485Z","shell.execute_reply":"2024-05-06T18:35:40.025760Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Collecting wurlitzer\n  Downloading wurlitzer-3.1.0-py3-none-any.whl.metadata (2.5 kB)\nDownloading wurlitzer-3.1.0-py3-none-any.whl (8.4 kB)\nInstalling collected packages: wurlitzer\nSuccessfully installed wurlitzer-3.1.0\nCollecting keras==2.15.0\n  Using cached keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\nUsing cached keras-2.15.0-py3-none-any.whl (1.7 MB)\nInstalling collected packages: keras\n  Attempting uninstall: keras\n    Found existing installation: keras 3.3.3\n    Uninstalling keras-3.3.3:\n      Successfully uninstalled keras-3.3.3\nSuccessfully installed keras-2.15.0\n","output_type":"stream"}]},{"cell_type":"code","source":"# Install Keras 3 last. See https://keras.io/getting_started/ for more details.\n!pip install -q -U keras-nlp\n","metadata":{"id":"UcGLzDeQ8NwN","papermill":{"duration":39.321226,"end_time":"2024-02-21T09:21:15.151995","exception":false,"start_time":"2024-02-21T09:20:35.830769","status":"completed"},"tags":[],"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-05-06T18:36:13.365517Z","iopub.execute_input":"2024-05-06T18:36:13.366060Z","iopub.status.idle":"2024-05-06T18:36:28.384259Z","shell.execute_reply.started":"2024-05-06T18:36:13.366001Z","shell.execute_reply":"2024-05-06T18:36:28.382392Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"!pip install keras","metadata":{"execution":{"iopub.status.busy":"2024-05-06T18:41:06.441465Z","iopub.execute_input":"2024-05-06T18:41:06.442357Z","iopub.status.idle":"2024-05-06T18:41:19.718389Z","shell.execute_reply.started":"2024-05-06T18:41:06.442306Z","shell.execute_reply":"2024-05-06T18:41:19.716832Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: keras in /opt/conda/lib/python3.10/site-packages (3.3.3)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from keras) (1.4.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from keras) (1.26.4)\nRequirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras) (13.7.0)\nRequirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras) (0.0.8)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.10/site-packages (from keras) (3.10.0)\nRequirement already satisfied: optree in /opt/conda/lib/python3.10/site-packages (from keras) (0.11.0)\nRequirement already satisfied: ml-dtypes in /opt/conda/lib/python3.10/site-packages (from keras) (0.2.0)\nRequirement already satisfied: typing-extensions>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from optree->keras) (4.9.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras) (2.17.2)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Import packages\n\nImport Keras and KerasNLP.","metadata":{"id":"FX47AUYrXwLK","papermill":{"duration":0.008053,"end_time":"2024-02-21T09:21:15.168461","exception":false,"start_time":"2024-02-21T09:21:15.160408","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import keras\nimport keras_nlp","metadata":{"id":"ww83zI9ToPso","papermill":{"duration":20.44507,"end_time":"2024-02-21T09:21:35.62369","exception":false,"start_time":"2024-02-21T09:21:15.17862","status":"completed"},"tags":[],"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-05-06T20:42:23.680017Z","iopub.execute_input":"2024-05-06T20:42:23.680976Z","iopub.status.idle":"2024-05-06T20:42:38.914237Z","shell.execute_reply.started":"2024-05-06T20:42:23.680926Z","shell.execute_reply":"2024-05-06T20:42:38.912954Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-05-06 20:42:26.645581: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-06 20:42:26.645812: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-06 20:42:26.838030: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np","metadata":{"execution":{"iopub.status.busy":"2024-05-06T20:42:38.916658Z","iopub.execute_input":"2024-05-06T20:42:38.917368Z","iopub.status.idle":"2024-05-06T20:42:38.922866Z","shell.execute_reply.started":"2024-05-06T20:42:38.917332Z","shell.execute_reply":"2024-05-06T20:42:38.921226Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"### Select a backend\n\nKeras is a high-level, multi-framework deep learning API designed for simplicity and ease of use. [Keras 3](https://keras.io/keras_3) lets you choose the backend: TensorFlow, JAX, or PyTorch. All three will work for this tutorial.","metadata":{"id":"Pm5cVOFt5YvZ","papermill":{"duration":0.012975,"end_time":"2024-02-21T09:21:35.649131","exception":false,"start_time":"2024-02-21T09:21:35.636156","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import os\n\nos.environ[\"KERAS_BACKEND\"] = \"jax\"  # Or \"tensorflow\" or \"torch\".","metadata":{"id":"7rS7ryTs5wjf","papermill":{"duration":0.020559,"end_time":"2024-02-21T09:21:35.678502","exception":false,"start_time":"2024-02-21T09:21:35.657943","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-06T20:42:38.924660Z","iopub.execute_input":"2024-05-06T20:42:38.925088Z","iopub.status.idle":"2024-05-06T20:42:38.939263Z","shell.execute_reply.started":"2024-05-06T20:42:38.925031Z","shell.execute_reply":"2024-05-06T20:42:38.937688Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Create a model\n\nKerasNLP provides implementations of many popular [model architectures](https://keras.io/api/keras_nlp/models/). In this tutorial, you'll create a model using `GemmaCausalLM`, an end-to-end Gemma model for causal language modeling. A causal language model predicts the next token based on previous tokens.\n\nCreate the model using the `from_preset` method:","metadata":{"id":"ZsxDCbLN555T","papermill":{"duration":0.008721,"end_time":"2024-02-21T09:21:35.698183","exception":false,"start_time":"2024-02-21T09:21:35.689462","status":"completed"},"tags":[]}},{"cell_type":"code","source":"gemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(\"gemma_1.1_instruct_2b_en\")","metadata":{"id":"yygIK9DEIldp","papermill":{"duration":113.918294,"end_time":"2024-02-21T09:23:29.630183","exception":false,"start_time":"2024-02-21T09:21:35.711889","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-06T20:42:38.942160Z","iopub.execute_input":"2024-05-06T20:42:38.942777Z","iopub.status.idle":"2024-05-06T20:44:35.074817Z","shell.execute_reply.started":"2024-05-06T20:42:38.942739Z","shell.execute_reply":"2024-05-06T20:44:35.073319Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"Attaching 'metadata.json' from model 'keras/gemma/keras/gemma_1.1_instruct_2b_en/3' to your Kaggle notebook...\nAttaching 'metadata.json' from model 'keras/gemma/keras/gemma_1.1_instruct_2b_en/3' to your Kaggle notebook...\nAttaching 'task.json' from model 'keras/gemma/keras/gemma_1.1_instruct_2b_en/3' to your Kaggle notebook...\nAttaching 'config.json' from model 'keras/gemma/keras/gemma_1.1_instruct_2b_en/3' to your Kaggle notebook...\nAttaching 'metadata.json' from model 'keras/gemma/keras/gemma_1.1_instruct_2b_en/3' to your Kaggle notebook...\nAttaching 'metadata.json' from model 'keras/gemma/keras/gemma_1.1_instruct_2b_en/3' to your Kaggle notebook...\nAttaching 'config.json' from model 'keras/gemma/keras/gemma_1.1_instruct_2b_en/3' to your Kaggle notebook...\nAttaching 'config.json' from model 'keras/gemma/keras/gemma_1.1_instruct_2b_en/3' to your Kaggle notebook...\nAttaching 'model.weights.h5' from model 'keras/gemma/keras/gemma_1.1_instruct_2b_en/3' to your Kaggle notebook...\nAttaching 'metadata.json' from model 'keras/gemma/keras/gemma_1.1_instruct_2b_en/3' to your Kaggle notebook...\nAttaching 'metadata.json' from model 'keras/gemma/keras/gemma_1.1_instruct_2b_en/3' to your Kaggle notebook...\nAttaching 'preprocessor.json' from model 'keras/gemma/keras/gemma_1.1_instruct_2b_en/3' to your Kaggle notebook...\nAttaching 'tokenizer.json' from model 'keras/gemma/keras/gemma_1.1_instruct_2b_en/3' to your Kaggle notebook...\nAttaching 'tokenizer.json' from model 'keras/gemma/keras/gemma_1.1_instruct_2b_en/3' to your Kaggle notebook...\nAttaching 'assets/tokenizer/vocabulary.spm' from model 'keras/gemma/keras/gemma_1.1_instruct_2b_en/3' to your Kaggle notebook...\nnormalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"`from_preset` instantiates the model from a preset architecture and weights. In the code above, the string `\"gemma_2b_en\"` specifies the preset architecture: a Gemma model with 2 billion parameters. (A Gemma model with 7 billion parameters is also available. To run the larger model in Colab, you need access to the premium GPUs available in paid plans. Alternatively, you can perform [distributed tuning on a Gemma 7B model](https://ai.google.dev/gemma/docs/distributed_tuning) on Kaggle or Google Cloud.)\n\nUse `summary` to get more info about the model:","metadata":{"id":"XrAWvsU6pI0E","papermill":{"duration":0.009095,"end_time":"2024-02-21T09:23:29.648821","exception":false,"start_time":"2024-02-21T09:23:29.639726","status":"completed"},"tags":[]}},{"cell_type":"code","source":"gemma_lm.summary()","metadata":{"id":"e5nEbTdApL7W","papermill":{"duration":0.067494,"end_time":"2024-02-21T09:23:29.72571","exception":false,"start_time":"2024-02-21T09:23:29.658216","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-06T18:45:29.288616Z","iopub.execute_input":"2024-05-06T18:45:29.289010Z","iopub.status.idle":"2024-05-06T18:45:29.373709Z","shell.execute_reply.started":"2024-05-06T18:45:29.288974Z","shell.execute_reply":"2024-05-06T18:45:29.370607Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mTokenizer (type)                                  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                            Vocab #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                   │                                             \u001b[38;5;34m256,000\u001b[0m │\n└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Tokenizer (type)                                   </span>┃<span style=\"font-weight: bold\">                                             Vocab # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                   │                                             <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        │   \u001b[38;5;34m2,506,172,416\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m524,288,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">524,288,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,506,172,416\u001b[0m (9.34 GB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,506,172,416\u001b[0m (9.34 GB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}]},{"cell_type":"markdown","source":"As you can see from the summary, the model has 2.5 billion trainable parameters.","metadata":{"id":"81KHdRYOrWYm","papermill":{"duration":0.010233,"end_time":"2024-02-21T09:23:29.749578","exception":false,"start_time":"2024-02-21T09:23:29.739345","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## Generate text\n\nNow it's time to generate some text! The model has a `generate` method that generates text based on a prompt. The optional `max_length` argument specifies the maximum length of the generated sequence.\n\nTry it out with the prompt `\"What is the meaning of life?\"`.","metadata":{"id":"FOBW7piN5-sl","papermill":{"duration":0.010186,"end_time":"2024-02-21T09:23:29.771881","exception":false,"start_time":"2024-02-21T09:23:29.761695","status":"completed"},"tags":[]}},{"cell_type":"code","source":"gemma_lm.generate(\"What is the meaning of life?\", max_length=64)","metadata":{"id":"aae5GHrdpj2_","papermill":{"duration":153.317812,"end_time":"2024-02-21T09:26:03.102408","exception":false,"start_time":"2024-02-21T09:23:29.784596","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-06T19:00:56.061336Z","iopub.execute_input":"2024-05-06T19:00:56.062784Z","iopub.status.idle":"2024-05-06T19:12:14.114703Z","shell.execute_reply.started":"2024-05-06T19:00:56.062722Z","shell.execute_reply":"2024-05-06T19:12:14.113651Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"'What is the meaning of life?\\n\\nThe meaning of life is a profound and multifaceted question that has captivated philosophers, theologians, and individuals for centuries. There is no single, universally accepted answer, as the meaning of life is often subjective, personal, and evolves throughout life.\\n\\n**Philosophical Perspectives:**\\n\\n*'"},"metadata":{}}]},{"cell_type":"markdown","source":"Try calling `generate` again with a different prompt.","metadata":{"id":"qH0eFH_DvYwM","papermill":{"duration":0.011582,"end_time":"2024-02-21T09:26:03.125363","exception":false,"start_time":"2024-02-21T09:26:03.113781","status":"completed"},"tags":[]}},{"cell_type":"code","source":"gemma_lm.generate(\"How does the brain work?\", max_length=64)","metadata":{"id":"VEyTnnNGvgGG","papermill":{"duration":124.920909,"end_time":"2024-02-21T09:28:08.056821","exception":false,"start_time":"2024-02-21T09:26:03.135912","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-06T19:49:15.919128Z","iopub.execute_input":"2024-05-06T19:49:15.919758Z","iopub.status.idle":"2024-05-06T20:00:50.242778Z","shell.execute_reply.started":"2024-05-06T19:49:15.919716Z","shell.execute_reply":"2024-05-06T20:00:50.241298Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"'How does the brain work?\\n\\n**The brain is a complex organ that is responsible for controlling and coordinating all bodily functions, including movement, thinking, and emotions.**\\n\\n**The brain is divided into two hemispheres, each of which is responsible for specific functions.**\\n\\n* **Left hemisphere:** Responsible for logical thinking,'"},"metadata":{}}]},{"cell_type":"markdown","source":"If you're running on JAX or TensorFlow backends, you'll notice that the second `generate` call returns nearly instantly. This is because each call to `generate` for a given batch size and `max_length` is compiled with XLA. The first run is expensive, but subsequent runs are much faster.","metadata":{"id":"vVlCnY7Gvm7U","papermill":{"duration":0.01103,"end_time":"2024-02-21T09:28:08.078435","exception":false,"start_time":"2024-02-21T09:28:08.067405","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"You can also provide batched prompts using a list as input:","metadata":{"id":"mw5XkiHU11Ft","papermill":{"duration":0.010923,"end_time":"2024-02-21T09:28:08.101562","exception":false,"start_time":"2024-02-21T09:28:08.090639","status":"completed"},"tags":[]}},{"cell_type":"code","source":"gemma_lm.generate(\n    [\"What is the meaning of life?\",\n     \"How does the brain work?\"],\n    max_length=64)","metadata":{"id":"xV6vs8_C2BGt","papermill":{"duration":284.668615,"end_time":"2024-02-21T09:32:52.781544","exception":false,"start_time":"2024-02-21T09:28:08.112929","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-06T20:00:50.244978Z","iopub.execute_input":"2024-05-06T20:00:50.245392Z","iopub.status.idle":"2024-05-06T20:02:57.873537Z","shell.execute_reply.started":"2024-05-06T20:00:50.245360Z","shell.execute_reply":"2024-05-06T20:02:57.872152Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"['What is the meaning of life?\\n\\nThe meaning of life is a profound and multifaceted question that has captivated philosophers, theologians, and individuals for centuries. There is no single, universally accepted answer, as the meaning of life is often subjective, personal, and evolves throughout life.\\n\\n**Philosophical Perspectives:**\\n\\n*',\n 'How does the brain work?\\n\\n**The brain is a complex organ that is responsible for controlling and coordinating all bodily functions, including movement, thinking, and emotions.**\\n\\n**The brain is divided into two hemispheres, each of which is responsible for specific functions.**\\n\\n* **Left hemisphere:** Responsible for logical thinking,']"},"metadata":{}}]},{"cell_type":"markdown","source":"### Optional: Try a different sampler\n\nYou can control the generation strategy for `GemmaCausalLM` by setting the `sampler` argument on `compile()`. By default, [`\"greedy\"`](https://keras.io/api/keras_nlp/samplers/greedy_sampler/#greedysampler-class) sampling will be used.\n\nAs an experiment, try setting a [`\"top_k\"`](https://keras.io/api/keras_nlp/samplers/top_k_sampler/) strategy:","metadata":{"id":"MaVWoSpo3XyY","papermill":{"duration":0.012673,"end_time":"2024-02-21T09:32:52.817322","exception":false,"start_time":"2024-02-21T09:32:52.804649","status":"completed"},"tags":[]}},{"cell_type":"code","source":"gemma_lm.compile(sampler=\"top_k\")\ngemma_lm.generate(\"What is the meaning of life?\", max_length=64)","metadata":{"id":"mx55VQpN4DAK","papermill":{"duration":151.788202,"end_time":"2024-02-21T09:35:24.618187","exception":false,"start_time":"2024-02-21T09:32:52.829985","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-06T20:02:57.875681Z","iopub.execute_input":"2024-05-06T20:02:57.876613Z","iopub.status.idle":"2024-05-06T20:14:50.345467Z","shell.execute_reply.started":"2024-05-06T20:02:57.876450Z","shell.execute_reply":"2024-05-06T20:14:50.343889Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"'What is the meaning of life?\\n\\nThis is a profound and enduring question that has occupied philosophers, theologians, and individuals for centuries. There is no single definitive answer, as the meaning of life is often subjective, personal, and evolves throughout our lives.\\n\\n**Philosophical Perspectives:**\\n\\n* **Existentialism'"},"metadata":{}}]},{"cell_type":"markdown","source":"While the default greedy algorithm always picks the token with the largest probability, the top-K algorithm randomly picks the next token from the tokens of top K probability.\n\nYou don't have to specify a sampler, and you can ignore the last code snippet if it's not helpful to your use case. If you'd like learn more about the available samplers, see [Samplers](https://keras.io/api/keras_nlp/samplers/).","metadata":{"id":"-okKgK4LfO0f","papermill":{"duration":0.010755,"end_time":"2024-02-21T09:35:24.640256","exception":false,"start_time":"2024-02-21T09:35:24.629501","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"Using fit function","metadata":{}},{"cell_type":"code","source":"gemma_lm.generate(\"Keras is a\", max_length=30)","metadata":{"execution":{"iopub.status.busy":"2024-05-06T20:14:50.348141Z","iopub.execute_input":"2024-05-06T20:14:50.349271Z","iopub.status.idle":"2024-05-06T20:20:22.319689Z","shell.execute_reply.started":"2024-05-06T20:14:50.349224Z","shell.execute_reply":"2024-05-06T20:20:22.318256Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"'Keras is a deep learning library for Python that provides a high-level interface to a wide range of deep learning models and algorithms.\\n\\n**'"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}